import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error
import numpy as np
import matplotlib.pyplot as plt

# Cargar el archivo Excel
file_path = '/content/Registros_CD4_Actualizada.xlsx'
df = pd.read_excel(file_path)

# Crear nuevas características
df['Relacion_Leucocitos_Linfocitos'] = df['LEUCOCITOS'] / df['LINFOCITOS']
df['Producto_Leucocitos_Linfocitos'] = df['LEUCOCITOS'] * df['LINFOCITOS']

# Preparar los datos
X = df[['LEUCOCITOS', 'LINFOCITOS', 'Relacion_Leucocitos_Linfocitos', 'Producto_Leucocitos_Linfocitos']]
y = df['CD4']

# Normalizar/Estándarizar los datos
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Dividir los datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# 1. Regresión Lineal
model_lr = LinearRegression()
model_lr.fit(X_train, y_train)
y_pred_lr = model_lr.predict(X_test)
mse_lr = mean_squared_error(y_test, y_pred_lr)

# 2. Regresión Polinomial
poly_features = PolynomialFeatures(degree=2)
X_poly = poly_features.fit_transform(X)
X_train_poly, X_test_poly, y_train_poly, y_test_poly = train_test_split(X_poly, y, test_size=0.2, random_state=42)

model_poly = LinearRegression()
model_poly.fit(X_train_poly, y_train_poly)
y_pred_poly = model_poly.predict(X_test_poly)
mse_poly = mean_squared_error(y_test_poly, y_pred_poly)

# 3. Árboles de Decisión
model_dt = DecisionTreeRegressor(random_state=42)
model_dt.fit(X_train, y_train)
y_pred_dt = model_dt.predict(X_test)
mse_dt = mean_squared_error(y_test, y_pred_dt)

# 4. Bosques Aleatorios
model_rf = RandomForestRegressor(n_estimators=100, random_state=42)
model_rf.fit(X_train, y_train)
y_pred_rf = model_rf.predict(X_test)
mse_rf = mean_squared_error(y_test, y_pred_rf)

# 5. Soporte Vectorial para Regresión (SVR)
model_svr = SVR(kernel='rbf')
model_svr.fit(X_train, y_train)
y_pred_svr = model_svr.predict(X_test)
mse_svr = mean_squared_error(y_test, y_pred_svr)

# 6. Redes Neuronales (MLPRegressor)
model_nn = MLPRegressor(hidden_layer_sizes=(10, 10, 10), max_iter=1000, random_state=42)
model_nn.fit(X_train, y_train)
y_pred_nn = model_nn.predict(X_test)
mse_nn = mean_squared_error(y_test, y_pred_nn)

# Ajuste de hiperparámetros del modelo Random Forest con Grid Search
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42), param_grid=param_grid,
                           cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)

# Mejor modelo
best_model = grid_search.best_estimator_
y_pred_best = best_model.predict(X_test)
mse_best = mean_squared_error(y_test, y_pred_best)

# Validación cruzada con el mejor modelo
cv_scores = cross_val_score(best_model, X_scaled, y, cv=5, scoring='neg_mean_squared_error')
mse_cv = -cv_scores.mean()

# Mostrar los resultados
print('Error cuadrático medio del modelo (Regresión Lineal):', mse_lr)
print('Error cuadrático medio del modelo (Regresión Polinomial):', mse_poly)
print('Error cuadrático medio del modelo (Árboles de Decisión):', mse_dt)
print('Error cuadrático medio del modelo (Bosques Aleatorios):', mse_rf)
print('Error cuadrático medio del modelo (SVR):', mse_svr)
print('Error cuadrático medio del modelo (Red Neuronal):', mse_nn)
print('Error cuadrático medio del mejor modelo (Grid Search):', mse_best)
print('Error cuadrático medio con validación cruzada:', mse_cv)

# Graficar los resultados
models = ['Linear Regression', 'Polynomial Regression', 'Decision Tree', 'Random Forest', 'SVR', 'Neural Network', 'Best Model (Grid Search)']
errors = [mse_lr, mse_poly, mse_dt, mse_rf, mse_svr, mse_nn, mse_best]

plt.figure(figsize=(12, 6))
plt.bar(models, errors, color='skyblue')
plt.xlabel('Model')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Comparison of Model Performance (MSE)')
plt.xticks(rotation=45)
plt.show()
